<!DOCTYPE html><html lang="en"><head><meta charSet="UTF-8"/><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="./web2/_next/static/css/bfe94c38b147c90b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="./web2/_next/static/chunks/webpack-fee0133d88b9653f.js"/><script src="./web2/_next/static/chunks/4bd1b696-c3f339bc29afdab9.js" async=""></script><script src="./web2/_next/static/chunks/517-9a591ae601d6b36d.js" async=""></script><script src="./web2/_next/static/chunks/main-app-40ff7d0cddb2da75.js" async=""></script><script src="./web2/_next/static/chunks/app/layout-f85352c086b772ac.js" async=""></script><script src="./web2/_next/static/chunks/173-fc558b54b5be890b.js" async=""></script><script src="./web2/_next/static/chunks/795-77b345457a57fcf5.js" async=""></script><script src="./web2/_next/static/chunks/970-ddd077a8b3224bbd.js" async=""></script><script src="./web2/_next/static/chunks/app/projects/ImageProcessing/Project2/page-75199214765cf9e2.js" async=""></script><script src="/mathjax/es5/tex-chtml.js" id="MathJax-script" async=""></script><meta http-equiv="X-UA-Compatible" content="IE=edge"/><link rel="icon" href="/web2/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="./web2/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div class="flex flex-col h-screen"><header class="items-stretch shadow-[0_5px_15px_rgba(0,0,0,0.35)]"><div class="md:hidden flex flex-row justify-between bg-black text-white relative z-50"><button type="button"></button></div><nav><ul class="flex justify-end bg-black text-center list-none "><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/">Home</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/projects/">Projects</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/education/">Education</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/hobbies/">Hobbies</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="https://github.com/TrustinN">Github</a></li></ul></nav></header><div class="flex-grow"><div><div class="text-center text-black p-20 row-span-2 row-start-1 row-end-2 flex flex-col flex-nowrap justify-center items-center w-full"><h1>Project 2: Fun With Filters and Frequencies</h1></div><div class="mx-[5vw]"><div class="flex flex-row flex-nowrap justify-center relative"><div class="flex flex-col flex-grow max-w-[60rem]"><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Edge Detection"><div><h2>Filters for Edge Detection</h2><p>Detecting edges is detecting areas where the pixel values change abruptly, corresponding to the magnitude of the gradient at that pixel. The filter uses the kernel matrix<span style="display:block">\begin{equation*} \begin{bmatrix} -1 &amp; 1 \end{bmatrix} \end{equation*}</span>and<span style="display:block">\begin{equation*} \begin{bmatrix} -1 \\ 1 \end{bmatrix}\end{equation*}</span>derived from the derivative:<span style="display:block">\begin{equation*}f_x(x, y) = f(x + 0.5, y) - f(x - 0.5, y) \end{equation*}</span>These kernels are convolved with the image to get the<!-- --> <span style="display:inline">\(x\)</span>and <span style="display:inline">\(y\)</span>components of the gradient. We then take the euclidean norm between the <span style="display:inline">\(x\)</span> and<!-- --> <span style="display:inline">\(y\)</span> components to get the magnitude. To obtain an output in terms of either zeros or ones, I used a threshold as a cutoff value to determine if the pixel was part of an edge or not. To do this, I normalized the gradient magnitude image and compared to the threshold with<span style="display:block">\begin{equation*} \lvert\text{img}[i][j] \rvert &lt; 3 \cdot \text{threshold}\end{equation*}</span>I found that normalization was important for filters that might scale up the pixel values.</p><p>To improve the edge detection, I used a gaussian blur which can be convolved with both the finite difference<!-- --> <span style="display:inline">\(x\)</span> and<!-- --> <span style="display:inline">\(y\)</span> filters to get the difference of gaussian filter. This is useful because it removes the high frequencies/details that might accidently be detected as edges. One difference between the filters is how convolving with a gaussian first makes the edges less sharp. Then the gradient&#x27;s magnitude is less, and I had to adjust the threshold to be lower. In the previous filter, I used a threshold of<!-- --> <span style="display:inline">\(0.8\)</span>, where all values above<!-- --> <span style="display:inline">\(3 * 0.8\)</span> were set to<!-- --> <span style="display:inline">\(1\)</span>. In this one, I adjusted the threshold to <span style="display:inline">\(0.5\)</span>.</p><p>Below on the left is the output using the finite difference filters and one the right is with the difference of gaussian filters. We can see that there is a difference in the bottom of the images. The finite difference filter picks up the high frequencies and details that come from the grass, which blurring the image with a gaussian suppresses these frequencies. So in the difference of gaussian image, the high frequencies of the grass are not captured. Another visible difference is the edge width captured. Since we are blurring the images, it would make sense that locally around an edge, the pixels would pick up a similar gradient as their neighbors.</p><p>The same result is achieved whether applying a gaussian blur to the image then finite difference filter or convolving the fd filter with a gaussian filter to obtain first, then applying the image. This is because convolution is associative.</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="fdCameraman" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FfiniteDiffCameraman.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FfiniteDiffCameraman.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FfiniteDiffCameraman.png&amp;w=828&amp;q=75"/><img alt="DOGCameraman" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FDOGCameraman.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FDOGCameraman.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2FDOGCameraman.png&amp;w=828&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Unsharp Filter"><div><h2>Image Sharpening</h2><p>To sharpen an image, I convoluted a gaussian filter with the image and subtracted the result from the original image to get the high frequencies. Then the high frequences are multiplied by some scalar value and added back to the original to get more detail. On the left is the original, and the right is the sharpened image:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="taj_original" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj%20copy.jpg&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj%20copy.jpg&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj%20copy.jpg&amp;w=828&amp;q=75"/><img alt="taj" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftaj.png&amp;w=828&amp;q=75"/><img alt="woods_original" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods%20copy.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods%20copy.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods%20copy.png&amp;w=828&amp;q=75"/><img alt="woods" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fwoods.png&amp;w=828&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Hybrid Images"><div><h2>Hybrid Images</h2><p>To get a hybrid image, I convoluted one with a gaussian filter and the other with the identity filter minus the gaussian filter (Laplacian filter). The two images are added together to get a hybrid image. As for choosing the threshold, I found that having a higher standard deviation for the Laplacian filter was more effective in bringing out the details of the high frequency picture.</p><p>In the frequency image, the cat image has a strong star shaped frequency because of the rotated image. The sharp edges in the image contribute to the amplitude. The same can be said about the derek picture because of the band at the top. Taking the hybrid image results in a frequency domain image that looks like an average of the previous two.</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="hybrid" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fderek_nutmeg.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fderek_nutmeg.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fderek_nutmeg.png&amp;w=828&amp;q=75"/><img alt="fourier" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ffourier.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ffourier.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ffourier.png&amp;w=828&amp;q=75"/></div><p>One failed example is a blending between a panda and bear. One problem that can make the hybrid less convincing is if the edges do not line up well:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="panda_bear" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fpanda_bear.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fpanda_bear.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fpanda_bear.png&amp;w=828&amp;q=75"/></div><p>Here is a more successful hybrid which is between a tennis ball and orange. This works well because the edges line up well:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="hairy_orange" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fhairy_orange.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fhairy_orange.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fhairy_orange.png&amp;w=828&amp;q=75"/><img alt="tennis" loading="lazy" width="400" height="400" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftennis.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftennis.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Ftennis.png&amp;w=828&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Gaussian and Lapacian Stacks"><div><h2>Gaussian and Laplacian Stacks</h2><p>The gaussian stack is obtained by repeating the gaussian convolution with the previous image and doubling the standard deviation of the gaussian at each level. I chose a standard deviation of 1 for the first level after the original image and a kernel size of<!-- --> <span style="display:inline">\(6 \cdot \sigma\) </span>to ensure that values outside the kernel would be close to<!-- --> <span style="display:inline">0</span>. As for the Laplacian stack, this is obtained by taking the pairwise difference of the an image in the Gaussian stack and the next image. This gives an image that captures a certain band of frequencies at each level. For both the Laplacian and Gaussian stacks, the last image contains a collection of the lowest frequencies of the image.</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="stack" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fstack.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fstack.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fstack.png&amp;w=828&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Multi-Resolution Blending"><div><h2>Multi-Resolution Blending</h2><p>To get a seemless blend of two images, both images are alpha blended at each level given by their Laplacian stacks. This ensures that a good window can be found to prevent ghosting (when the window size is too big for the frequencies) or cropping of major details (when the window size is too small for the given frequencies). Blending at each level ensures that a good window size is chosen for the set of frequencies at each level. To get the blend at each level, a Gaussian stack of the image mask is used, which provides a larger window for the lower frequencies and a smaller window for the higher ones. A diagram of the blending at each level is shown below along with the gray and colored blend:</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="orple_color" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple.png&amp;w=828&amp;q=75"/><img alt="orple_gray" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_gray.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_gray.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_gray.png&amp;w=828&amp;q=75"/><img alt="orple_stack" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_stack.png&amp;w=828&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_stack.png&amp;w=1920&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Forple_stack.png&amp;w=1920&amp;q=75"/></div><p>Here is an attempt at putting leaves on a tree with an irregular mask:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="tree1" loading="lazy" width="400" height="200" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree1_copy.jpg&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree1_copy.jpg&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree1_copy.jpg&amp;w=828&amp;q=75"/><img alt="tree2" loading="lazy" width="400" height="200" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree2_copy.jpeg&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree2_copy.jpeg&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Ftree2_copy.jpeg&amp;w=828&amp;q=75"/><img alt="leaves_on_tree" loading="lazy" width="400" height="200" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree.png&amp;w=828&amp;q=75"/><img alt="leaves_on_tree_stack" loading="lazy" width="800" height="600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree_stack.png&amp;w=828&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree_stack.png&amp;w=1920&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fleaves_on_tree_stack.png&amp;w=1920&amp;q=75"/></div><p>Finally, here is a combination of a donut and bagel:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="donut" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdonut2%20copy.jpeg&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdonut2%20copy.jpeg&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdonut2%20copy.jpeg&amp;w=828&amp;q=75"/><img alt="bagel" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fbagel2%20copy.jpeg&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fbagel2%20copy.jpeg&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fbagel2%20copy.jpeg&amp;w=828&amp;q=75"/><img alt="dogel" loading="lazy" width="400" height="300" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel.png&amp;w=640&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel.png&amp;w=828&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel.png&amp;w=828&amp;q=75"/><img alt="dogel_stack" loading="lazy" width="800" height="800" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel_stack.png&amp;w=828&amp;q=75 1x, /web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel_stack.png&amp;w=1920&amp;q=75 2x" src="/web2/_next/image?url=%2Fprojects%2FImageProcessing%2FProject2%2Fmedia%2Fspline%2Fdogel_stack.png&amp;w=1920&amp;q=75"/></div></div></article></div></section></div><div class="block flex-grow"><div class="max-w-[80%] mx-auto h-full"><div class="sticky top-[20%] p-4 pl-6 border-1 border-black border-solid rounded-[1rem] bg-black shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-auto  max-h-[60vh] overflow-y-auto "><nav><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Edge Detection">Edge Detection</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Unsharp Filter">Unsharp Filter</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Hybrid Images">Hybrid Images</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Gaussian and Lapacian Stacks">Gaussian and Lapacian Stacks</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Multi-Resolution Blending">Multi-Resolution Blending</a></ul></nav></div></div></div></div></div></div></div><footer class="w-full bg-black text-center p-4 text-white shadow-[0_-5px_15px_rgba(0,0,0,0.35)]"><div>&lt;&lt;&lt; Â© Trustin Nguyen &gt;&gt;&gt;</div><div><a class="text-white hover:text-gray-300 hover:scale-100 focus:text-gray-300 focus:scale-100" href="#"> <!-- -->Back to Top<!-- --> </a></div></footer></div><script src="./web2/_next/static/chunks/webpack-fee0133d88b9653f.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[4547,[],\"ClientSegmentRoot\"]\n3:I[7249,[\"177\",\"static/chunks/app/layout-f85352c086b772ac.js\"],\"default\"]\n4:I[5244,[],\"\"]\n5:I[3866,[],\"\"]\n7:I[7033,[],\"ClientPageRoot\"]\n8:I[4291,[\"173\",\"static/chunks/173-fc558b54b5be890b.js\",\"795\",\"static/chunks/795-77b345457a57fcf5.js\",\"970\",\"static/chunks/970-ddd077a8b3224bbd.js\",\"868\",\"static/chunks/app/projects/ImageProcessing/Project2/page-75199214765cf9e2.js\"],\"default\"]\nb:I[6213,[],\"OutletBoundary\"]\nd:I[6213,[],\"MetadataBoundary\"]\nf:I[6213,[],\"ViewportBoundary\"]\n11:I[4835,[],\"\"]\n:HL[\"./web2/_next/static/css/bfe94c38b147c90b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"hqkY4uBU9VG_5wK1VJZaV\",\"p\":\"./web2\",\"c\":[\"\",\"projects\",\"ImageProcessing\",\"Project2\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"ImageProcessing\",{\"children\":[\"Project2\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"./web2/_next/static/css/bfe94c38b147c90b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"Component\":\"$3\",\"slots\":{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]},\"params\":{},\"promise\":\"$@6\"}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"ImageProcessing\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"Project2\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\",\"Project2\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L7\",null,{\"Component\":\"$8\",\"searchParams\":{},\"params\":\"$0:f:0:1:1:props:children:1:props:params\",\"promises\":[\"$@9\",\"$@a\"]}],null,[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"c7i50n6d-1z0pc_hercId\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n9:{}\na:{}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/web2/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script></body></html>