<!DOCTYPE html><html lang="en"><head><meta charSet="UTF-8"/><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="./_next/static/css/bfe94c38b147c90b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="./_next/static/chunks/webpack-341aa4a4d509aee2.js"/><script src="./_next/static/chunks/4bd1b696-c3f339bc29afdab9.js" async=""></script><script src="./_next/static/chunks/517-2e2bcfa1c8397427.js" async=""></script><script src="./_next/static/chunks/main-app-7533fffed5a02725.js" async=""></script><script src="./_next/static/chunks/app/layout-52a546404f3946aa.js" async=""></script><script src="./_next/static/chunks/173-fc558b54b5be890b.js" async=""></script><script src="./_next/static/chunks/795-77b345457a57fcf5.js" async=""></script><script src="./_next/static/chunks/970-273da32e793c59cb.js" async=""></script><script src="./_next/static/chunks/app/projects/ImageProcessing/Project3/page-94061cb127d48dad.js" async=""></script><script src="/mathjax/es5/tex-chtml.js" id="MathJax-script" async=""></script><meta http-equiv="X-UA-Compatible" content="IE=edge"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="./_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div class="flex flex-col h-screen"><header class="items-stretch shadow-[0_5px_15px_rgba(0,0,0,0.35)]"><div class="md:hidden flex flex-row justify-between bg-black text-white relative z-50"><button type="button"></button></div><nav><ul class="flex justify-end bg-black text-center list-none "><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/">Home</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/projects/">Projects</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/education/">Education</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/hobbies/">Hobbies</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="https://github.com/TrustinN">Github</a></li></ul></nav></header><div class="flex-grow"><div><div class="text-center text-black p-20 row-span-2 row-start-1 row-end-2 flex flex-col flex-nowrap justify-center items-center w-full"><h1>Project 3: Face Morphing and Modeling a Photo Collection</h1></div><div class="mx-[5vw]"><div class="flex flex-row flex-nowrap justify-center relative"><div class="flex flex-col flex-grow max-w-[60rem]"><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Defining Corresopndences"><div><h2>Defining Correspondences</h2><p>To morph one image to another, I would need to define keypoints in both images such that one image&#x27;s keypoints map to the other. I used python&#x27;s ginput function from matplotlib to define the keypoints:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="keypoints" loading="lazy" width="1100" height="680" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FKeyPointsPart1.png&amp;w=1200&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FKeyPointsPart1.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FKeyPointsPart1.png&amp;w=3840&amp;q=75"/></div><p>In selecting the keypoints, I had to make sure that close keypoints were not colinear to ensure that there was a triangulation. Also important was ensuring that the resulting triangles well partitioned the image such that no two different elements were in the same triangle. For example, if a triangle corresponding to the first image captured some of the hair and the background while the other did not, a fragment of the hair would morph inconsitantly with the rest of the hair. Finally, keypoints were set in the corners to ensure that the entire image was morphed and not just the head.</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="keypoints" loading="lazy" width="920" height="740" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphDelaunay.png&amp;w=1080&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphDelaunay.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphDelaunay.png&amp;w=1920&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="The Midway Face"><div><h2>Computing the Midway Face</h2><div><p>To get the midway face, the average of the keypoints were first calculated to determine the keypoints on the midway face. Delauney triangulation gave triangles that indexed into both the keypoints for the midway face along with the keypoints for the two images to be morphed. Using this, the affine transformation for mapping the midway triangle&#x27;s vertices on each of the two image&#x27;s triangle&#x27;s vertices could be computed. This allowed me to pull the rgb pixel values from both the source images, interpolated, to set in the midway image&#x27;s triangle. As for the details of the implementation, I created an<!-- --> <code>inverseWarp(source, sourceTri, dest, destTri, color=True)</code>function which uses the pixel values in the source image located at the sourceTriangle. Using scipy&#x27;s griddata method, I used this data to interpolate the values for the destination triangle. With skimage&#x27;s polygon method, I could get the indices for the destination triangle <code>destRR, destCC = polygon(destTri)</code> <!-- -->such that<code>dest[destRR, destCC] = res</code>, where<code>res</code> is the interpolated data. I used the<!-- --> <code>inverseWarp</code> function over all the simplices in the triangulation to get two morphs from the original images to the midway face.</p></div><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="midwayFace" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMidwayFace.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMidwayFace.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMidwayFace.png&amp;w=1920&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Morph Sequence"><div><h2>The Morph Sequence</h2><div class="float-right m-4 max-w-5xl"><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="morphSequence" loading="lazy" width="600" height="772" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphSequence.gif&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphSequence.gif&amp;w=1200&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FmorphSequence.gif&amp;w=1200&amp;q=75"/></div></div><p>All that is left is to calculate frames between image1 and the midway face and between the midway face and image2 to get a morph sequence from image1 to image2. This was done by first setting the start and target images for the current frame such that the current frame&#x27;s image was somewhere between the start and target images. Then I used linear interpolation to determine where the keypoints lie in the current frame. This is determined by<!-- --> <span style="display:inline">\(warpFrac\)</span> which lies between 0 and 1, 0 being the start of the morph and 1 being the end. Then the current keypoints are given by<!-- --> <span style="display:inline">\(startKp + warpFrac \cdot (targetKp - startKp)\)</span> <!-- -->if<span style="display:inline">\(warpFrac &lt; 0.5\)</span>. If<!-- --> <span style="display:inline">\(warpFrac &gt; 0.5\)</span>, I used<!-- --> <span style="display:inline">\(2 \cdot warpFrac - 1\)</span>. After warping the start and target images to the new keypoints, a dissolve fraction was used to determine the blend of the two results for the current frame in a similar manner to the warp fraction.</p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Population Mean Face"><div><h2>Population Mean Face</h2><p>To get the mean face, I used the faces from the FEI database. Getting the mean face is adding all the images and dividing by the number of images.</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="AverageNeutralFace" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageNeutralFace.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageNeutralFace.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageNeutralFace.png&amp;w=1920&amp;q=75"/><img alt="AverageSmilingFace" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageSmilingFace.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageSmilingFace.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAverageSmilingFace.png&amp;w=1920&amp;q=75"/></div><p>To morph a given face, <span style="display:inline">\(f\)</span>, and its keypoints, <span style="display:inline">\(f_k\)</span>, to the average face, I used the same method for computing the midway face. Using the average keypoints computed for the average face, I got data for it by interpolating from the data given on the triangles<span style="display:inline">\(f[f_k[simplex]]\)</span>. Here are some results, where the images are shown in pairs. The left image is the original and the right is the image morphed to the average:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="SampleMorphs" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FSampleMorphedToAvg.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FSampleMorphedToAvg.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FSampleMorphedToAvg.png&amp;w=1920&amp;q=75"/></div><p>Using the annotatations for the image, I labeled my face with keypoints in the same order. I noticed that there were some keypoints missing for the top of the forehead, so I added them to get more accurate results. Here are pictures of my face morphed to the average and the average morphed to my face:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="AverageAnyMyFaceKp" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAvgAndMyFaceKp.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAvgAndMyFaceKp.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FAvgAndMyFaceKp.png&amp;w=1920&amp;q=75"/><img alt="NewAverageAnyMyFaceKp" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceKp.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceKp.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceKp.png&amp;w=1920&amp;q=75"/><img alt="NewAverageAnyMyFaceDelaunay" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceDelaunay.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceDelaunay.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FNewAvgAndMyFaceDelaunay.png&amp;w=1920&amp;q=75"/><img alt="MyFaceAvgMorphs" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMyFaceAvgMorphs.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMyFaceAvgMorphs.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FMyFaceAvgMorphs.png&amp;w=1920&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Caricature"><div><h2>Caricature</h2><div class="float-right m-4 undefined"><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="Caricature1" loading="lazy" width="640" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FCaricature1.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FCaricature1.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject3%2Fmedia%2FCaricature1.png&amp;w=1920&amp;q=75"/></div></div><p>To get a caricature I extrapolated data from the mean. I took a difference<!-- --> <span style="display:inline">\(myface - mean = diff\)</span> and for <span style="display:inline">\(alpha &lt; 1\)</span> or<!-- --> <span style="display:inline">\(alpha &lt; 0\)</span>, I computed<!-- --> <span style="display:inline">\(alpha \cdot mean + (1 - alpha) \cdot myface\)</span>.</p></div></article></div></section></div><div class="block flex-grow"><div class="max-w-[80%] mx-auto h-full"><div class="sticky top-[20%] p-4 pl-6 border-1 border-black border-solid rounded-[1rem] bg-black shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-auto  max-h-[60vh] overflow-y-auto "><nav><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Defining Corresopndences">Defining Corresopndences</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#The Midway Face">The Midway Face</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Morph Sequence">Morph Sequence</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Population Mean Face">Population Mean Face</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Caricature">Caricature</a></ul></nav></div></div></div></div></div></div></div><footer class="w-full bg-black text-center p-4 text-white shadow-[0_-5px_15px_rgba(0,0,0,0.35)]"><div>&lt;&lt;&lt; © Trustin Nguyen &gt;&gt;&gt;</div><div><a class="text-white hover:text-gray-300 hover:scale-100 focus:text-gray-300 focus:scale-100" href="#"> <!-- -->Back to Top<!-- --> </a></div></footer></div><script src="./_next/static/chunks/webpack-341aa4a4d509aee2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[4547,[],\"ClientSegmentRoot\"]\n3:I[7249,[\"177\",\"static/chunks/app/layout-52a546404f3946aa.js\"],\"default\"]\n4:I[5244,[],\"\"]\n5:I[3866,[],\"\"]\n7:I[7033,[],\"ClientPageRoot\"]\n8:I[4938,[\"173\",\"static/chunks/173-fc558b54b5be890b.js\",\"795\",\"static/chunks/795-77b345457a57fcf5.js\",\"970\",\"static/chunks/970-273da32e793c59cb.js\",\"71\",\"static/chunks/app/projects/ImageProcessing/Project3/page-94061cb127d48dad.js\"],\"default\"]\nb:I[6213,[],\"OutletBoundary\"]\nd:I[6213,[],\"MetadataBoundary\"]\nf:I[6213,[],\"ViewportBoundary\"]\n11:I[4835,[],\"\"]\n:HL[\"./_next/static/css/bfe94c38b147c90b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"tlwXbO0V3Ne-VwUPMHTZp\",\"p\":\".\",\"c\":[\"\",\"projects\",\"ImageProcessing\",\"Project3\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"ImageProcessing\",{\"children\":[\"Project3\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"./_next/static/css/bfe94c38b147c90b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"Component\":\"$3\",\"slots\":{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]},\"params\":{},\"promise\":\"$@6\"}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"ImageProcessing\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"Project3\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\",\"Project3\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L7\",null,{\"Component\":\"$8\",\"searchParams\":{},\"params\":\"$0:f:0:1:1:props:children:1:props:params\",\"promises\":[\"$@9\",\"$@a\"]}],null,[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"m_-mXjBU8nC1bpSyEPn0f\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n9:{}\na:{}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script></body></html>