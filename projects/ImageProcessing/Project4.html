<!DOCTYPE html><html lang="en"><head><meta charSet="UTF-8"/><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="./_next/static/css/bfe94c38b147c90b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="./_next/static/chunks/webpack-341aa4a4d509aee2.js"/><script src="./_next/static/chunks/4bd1b696-c3f339bc29afdab9.js" async=""></script><script src="./_next/static/chunks/517-2e2bcfa1c8397427.js" async=""></script><script src="./_next/static/chunks/main-app-7533fffed5a02725.js" async=""></script><script src="./_next/static/chunks/app/layout-52a546404f3946aa.js" async=""></script><script src="./_next/static/chunks/173-fc558b54b5be890b.js" async=""></script><script src="./_next/static/chunks/795-77b345457a57fcf5.js" async=""></script><script src="./_next/static/chunks/970-273da32e793c59cb.js" async=""></script><script src="./_next/static/chunks/app/projects/ImageProcessing/Project4/page-ba1dac737234bc18.js" async=""></script><script src="/mathjax/es5/tex-chtml.js" id="MathJax-script" async=""></script><meta http-equiv="X-UA-Compatible" content="IE=edge"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="./_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div class="flex flex-col h-screen"><header class="items-stretch shadow-[0_5px_15px_rgba(0,0,0,0.35)]"><div class="md:hidden flex flex-row justify-between bg-black text-white relative z-50"><button type="button"></button></div><nav><ul class="flex justify-end bg-black text-center list-none "><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/">Home</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/projects/">Projects</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/education/">Education</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="/hobbies/">Hobbies</a></li><li><a class="block p-4 transform scale-90 transition-transform duration-250 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 hover:text-gray-300 focus:text-gray-300 hover:bg-gray-800" href="https://github.com/TrustinN">Github</a></li></ul></nav></header><div class="flex-grow"><div><div class="text-center text-black p-20 row-span-2 row-start-1 row-end-2 flex flex-col flex-nowrap justify-center items-center w-full"><h1>Project 4: Image Warping and Mosaicing</h1></div><div class="mx-[5vw]"><div class="flex flex-row flex-nowrap justify-center relative"><div class="flex flex-col flex-grow max-w-[60rem]"><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Homographies"><div><h2>Recovering the Homographies</h2><p>A homography is given by a transformation sending<!-- --> <span style="display:inline">\(v_{1} = \begin{bmatrix} x \\ y \\ 1 \end{bmatrix}\)</span> <!-- -->to<!-- --> <span style="display:inline">\(v_{2} = \begin{bmatrix} x^{\prime} \\ y^{\prime} \\ 1 \end{bmatrix}\)</span> <!-- -->mod scaling through a matrix:<span style="display:block">\begin{equation*} c \begin{bmatrix} x^{\prime} \\ y^{\prime} \\ 1 \end{bmatrix} = \begin{bmatrix} h_{1} &amp; h_{2} &amp; h_{3} \\ h_{4} &amp; h_{5} &amp; h_{6} \\ h_{7} &amp; h_{8} &amp; 1 \end{bmatrix} \begin{bmatrix} x \\ y \\ 1 \end{bmatrix} \end{equation*}</span>Multiplying everything out, we get:<span style="display:block">\begin{align*} cx^{\prime} &amp;= h_{1}x + h_{2}y + h_{3} \\ cy^{\prime} &amp;= h_{4}x + h_{5}y + h_{6} \\ c &amp;= h_{7}x + h_{8}y + 1 \end{align*}</span>and substituting:<span style="display:block">\begin{align*} (h_{7}x + h_{8}y + 1)x^{\prime} &amp;= h_{1}x + h_{2}y + h_{3} \\ (h_{7}x + h_{8}y + 1)y^{\prime} &amp;= h_{4}x + h_{5}y + h_{6} \end{align*}</span>will give the system of equations:<span style="display:block">\begin{align*} h_{1}x + h_{2}y + h_{3} + 0h_{4} + 0h_{5} + 0h_{6} - h_{7}xx^{\prime} - h_{8}yx^{\prime} - 1x^{\prime} &amp;= 0 \\ 0h_{1} + 0h_{2} + 0h_{3} + h_{4}x + h_{5}y + h_{6} - h_{7}xy^{\prime} - h_{8}yy^{\prime} - 1y^{\prime} &amp;= 0 \end{align*}</span>This gives a way to solve for the entries of the matrix<!-- --> <span style="display:inline">H</span> through a different linear equation <span style="display:inline">\(Ax = b\)</span> where<!-- --> <span style="display:inline">\(A\)<!-- --> </span> is a<!-- --> <span style="display:inline">\(2 \times 8\)</span> matrix,<span style="display:inline">x </span> is the vector containing the entries <span style="display:inline">\(h_1, \ldots, h_8\)</span>, and <span style="display:inline">\(b\)</span> is the vector containing the values<!-- --> <span style="display:inline">\(x&#x27;, y&#x27;\)</span>. This is extendable to include more points in our homography mapping and can be solved through least squares to find the projective mapping</p><p>Here is an example of the point correspondences that I used to compute the homography</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="kps1" loading="lazy" width="913" height="325" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fkps1.png&amp;w=1080&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fkps1.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fkps1.png&amp;w=1920&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Image Warping"><div><h2>Warping the Image</h2><p>This process was very similar to the last project, but instead, the warp would be determined by four corners under the homography transformation. After calculating the new corners, a resulting image would be set to encompass the warped image. The pixel values in the new image <span style="display:inline">\(B\)</span> would be determined by where the pixel landed under the transformation<!-- --> <span style="display:inline">\(H^{-1}\)</span></p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="inverseWarp" loading="lazy" width="560" height="380" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ImageProcessing/Project4/media/Part1/inverseWarp.svg"/></div><p>Since the pixel location under $H^<!-- -->-1<!-- -->$ is not exact, I used griddata to interpolate for the pixel value using the location and values in the original image as the data. Here is the result of the warp on the left and the base image of the panorama on the right</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="homography1" loading="lazy" width="900" height="370" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fhomography1.png&amp;w=1080&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fhomography1.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fhomography1.png&amp;w=1920&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Rectification"><div><h2>Rectification</h2><p>One interesting application of image warping by homography is to emulate a snapshot of the image from a different perspective. In changing the camera angle via homography, we attempt to capture the pixels outside the image, and therefore, the image is shifted further to the peripheral making it seem distorted. This is why rectification will work well when dealing with small shifts in the perspective. Here are some examples that I ran my code on:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="PreRectified book" loading="lazy" width="950" height="640" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_original.png&amp;w=1080&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_original.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_original.png&amp;w=1920&amp;q=75"/><img alt="Rectified book" loading="lazy" width="1600" height="1000" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_rectified.png&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_rectified.png&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fbook_rectified.png&amp;w=3840&amp;q=75"/><img alt="PreRectified sign" loading="lazy" width="660" height="800" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fsign_original.png&amp;w=750&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fsign_original.png&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fsign_original.png&amp;w=1920&amp;q=75"/><img alt="Rectified Sign" loading="lazy" width="3200" height="1600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fsign_rectified.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Frectified%2Fsign_rectified.png&amp;w=3840&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Image Mosaic"><div><h2>Image Mosaic</h2><p>The first step is to correctly align the images. Here I used zero padding:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="padded_homography" loading="lazy" width="550" height="200" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fpadded_homography.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fpadded_homography.png&amp;w=1200&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fpadded_homography.png&amp;w=1200&amp;q=75"/></div><p>The images cannot be directly added together and averaged at the intersection because there is different lighting and exposure across images. To fix this, I created a set of two images. Let the image on the left be image <span style="display:inline">\(A\)</span> and the image on the right be image<!-- --> <span style="display:inline">\(B\)</span>. In one image, image<!-- --> <span style="display:inline">\(A\)</span> would dominate, meaning that on<!-- --> <span style="display:inline">\(\text{image}(A) \cap \text{image} B\)</span>, I would set the pixel values to be that of image<!-- --> <span style="display:inline">\(A\)</span>. The other case would be an image where image <span style="display:inline">\(B\)</span> <!-- -->dominates. Here is an example of creating these images:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="im1dominant" loading="lazy" width="1000" height="250" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim1dominant.png&amp;w=1080&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim1dominant.png&amp;w=2048&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim1dominant.png&amp;w=2048&amp;q=75"/><img alt="im2dominant" loading="lazy" width="500" height="140" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim2dominant.png&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim2dominant.png&amp;w=1080&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fim2dominant.png&amp;w=1080&amp;q=75"/></div><p>Then for the blending, notice that image<!-- --> <span style="display:inline">\(A\)</span> captures the scene more accurately the closer the pixels are to the center of image<!-- --> <span style="display:inline">\(A\)</span>. The same goes for image<!-- --> <span style="display:inline">\(B\)</span>. So to get a blend, a linear interpolation between their centers can be calculated (through griddata) and put into a mask. The output image is given by<span style="display:block">\begin{equation*} \text{mosaic} = \text{mask} \cdot \text{dominantA} + (1 - \text{mask}) \cdot \text{dominantB} \end{equation*}</span>Here is an iterative approach to the blending:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="blend0" loading="lazy" width="430" height="560" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend0.jpeg&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend0.jpeg&amp;w=1080&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend0.jpeg&amp;w=1080&amp;q=75"/><img alt="blend1" loading="lazy" width="400" height="467" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend1.jpeg&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend1.jpeg&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend1.jpeg&amp;w=828&amp;q=75"/><img alt="blend2" loading="lazy" width="380" height="410" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend2.jpeg&amp;w=384&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend2.jpeg&amp;w=828&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend2.jpeg&amp;w=828&amp;q=75"/><img alt="blend3" loading="lazy" width="480" height="480" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend3.jpeg&amp;w=640&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend3.jpeg&amp;w=1080&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fblending%2Fblend3.jpeg&amp;w=1080&amp;q=75"/></div><p>Although it is possible to separate the frequencies into high and low frequencies, blending the lower frequencies and choosing one of the higher frequencies, I had more success just directly blending the images. This is because a small misalignment of about 5 pixels can cause the high frequencies in one image to look discontinuous with the high frequencies in the other. This caused the railing to look cutoff at certain areas in my previous blends. Here is the final result without separating the frequencies:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="mosaic" loading="lazy" width="6900" height="3000" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fmosaic.png&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart1%2Fmosaic.png&amp;w=3840&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Corner Detection"><div><h2>Detecting Corner Features</h2><p>The Harris corner detector defines a corner centered on pixel<!-- --> <span style="display:inline">\(u, v\)</span> on some window of size<!-- --> <span style="display:inline">\(w\)</span> if for any shift in<!-- --> <span style="display:inline">\(x\)</span> or<!-- --> <span style="display:inline">\(y\)</span>, the squared difference between the shifted window and the original is non-zero.</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="harris corner def" loading="lazy" width="1120" height="800" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ImageProcessing/Project4/media/Part2/harris_corner_def.svg"/></div><p>We notice that when the red window is over a monocolor surface, shifts of the window in either the<!-- --> <span style="display:inline">\(x\)</span> or<!-- --> <span style="display:inline">\(y\)</span> direction results in no change in what the window sees. For the line example, the window only sees a change when we move in the vertical direction. When the window is shifted in a horizontal direction, the difference is<!-- --> <span style="display:inline">\(0\)</span>. This would be defined as an edge. Finally, we have the vertex of a triangle. In this case, any change in either the <span style="display:inline">\(x\)</span>or <span style="display:inline">\(y\)</span> direction results in a change in what the window sees. We can also plot the squared difference as a function over displacement of the window at a pixel. Here&#x27;s what it would look like for the above examples:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="window differences" loading="lazy" width="1120" height="800" decoding="async" data-nimg="1" class="w-full" style="color:transparent" src="/projects/ImageProcessing/Project4/media/Part2/corner_diff.svg"/></div><p>The first one is circular because at the origin, displacement is,<!-- --> <span style="display:inline">\((0, 0)\)</span> and as we have more displacement, the error increases between the original and the displaced window. The second one is like a valley because along the horizontal direction, displacement does not change what the window sees, so the error is <span style="display:inline">\(0\)</span>. As we move in the vertical direction, the error increase. Finally, if the window is over a monocolor surface, the error will be<!-- --> <span style="display:inline">\(0\)</span>.</p><p>Implementation of finding the harris corners and corner strength was given as starter code. Also, I was not able to plot all harris corners because there were too many detected, and it would completely blanket the image. A view of some of the filtered out corners will be shown in the next section.</p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Feature Descriptors"><div><h2>Extracting Feature Descriptors</h2><p>Feature descriptors describe what is happening locally at a pixel. They usually small<!-- --> <span style="display:inline">\(8 \times 8\)</span> pixels, and can be used to match features across images. This is done by the squared difference between the descriptors. At the original resolution, however, the descriptors are not robust to small errors such as differences in orientation and perspective. To fix this, a<!-- --> <span style="display:inline">\(40 \times 40\)</span> window is sampled around the pixel, convolved with a Gaussian kernel, and downsampled by <span style="display:inline">\(5\)</span>. The descriptor is finally normalized to make it resilient to differences in luminence:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="feature descriptor bush" loading="lazy" width="2300" height="900" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc.jpg&amp;w=3840&amp;q=75"/><img alt="feature descriptor building" loading="lazy" width="800" height="2100" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc2.jpg&amp;w=828&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc2.jpg&amp;w=1920&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc2.jpg&amp;w=1920&amp;q=75"/></div><p>And here are all the feature descriptors extracted from the images:</p><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="doe descriptor left" loading="lazy" width="1250" height="980" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_left.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_left.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_left.jpg&amp;w=3840&amp;q=75"/><img alt="doe descriptor right" loading="lazy" width="1150" height="850" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_right.jpg&amp;w=1200&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_right.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_desc_right.jpg&amp;w=3840&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Feature Matching"><div><h2>Feature Matching</h2><p>Notice that in the previous picture, some feature descriptors in one image are not present in the other. So we need a way to throw away feature descriptors as well as match the remaining feature descriptors. One problem with finding the nearest neighbor from one image to another by squared error is that two descriptors could yield a small error, but the probability of it being an incorrect match shares significant overlap with the probability that it is a correct match:</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="nearest neighbor matching error" loading="lazy" width="1850" height="850" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fnn_matching.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fnn_matching.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fnn_matching.jpg&amp;w=3840&amp;q=75"/></div><p>This is seen on the left where a nearest neighbor squared error of<!-- --> <span style="display:inline">\(10\)</span> will not be a strong indicator of whether the pair is a correct match or not. One instance in which this might be a problem is if the descriptors are not present in both images. In the case that the descriptor from one image matches with the descriptor in the other, we have an outlier match, which will throw off the key point matching.</p><p>In contrast, we can instead look at the ratio between the closest match and the second closest match error. This gives a much better separation between the probability density of correct matches vs incorrect matches. The algorithm is reduce to setting the threshold. If the ratio of the error is high, then we can reject both descriptors as being a part of the final match. If the ratio is low, then we have found a match between the descriptor and its nearest neighbor.</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="Doe feature matching" loading="lazy" width="1900" height="780" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fdoe_matching.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fdoe_matching.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fdoe_matching.jpg&amp;w=3840&amp;q=75"/></div><p>Here, the white feature descriptors are from before feature matching. The red is after feature matching. Notice that the feature descriptors that are preserved tend to be on the overlap region of the two images.</p></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Robust Homography"><div><h2>Robust Homography</h2><p>All that is left is to produce the homography. One problem we have is that many of the feature descriptors do not represent a true match. For example, in the right image below, there is a red feature descriptor in the bottom right corner, which clearly lies outside of the image on the left. To make the homography robust to incorrect matches, we can use the RANSAC method.</p><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="feature correspondences" loading="lazy" width="1800" height="700" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_corres.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_corres.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Ffeat_corres.jpg&amp;w=3840&amp;q=75"/></div><p>RANSAC is a statistical algorithm which, for a chosen set of data, finds the inliers and outliers given our distribution. In our example, given four points which define a homography, we want to see how likely the homography on these points is to be the true homography. To do this, we compute the homography on the four points, and for every other point in the same image, we apply the homography. We then see if its matching feature descriptor lie within half a pixel of each other. If they do, then we classify them as an inlier, meaning they agree with the homography, otherwise, they are an outlier. The problem then reduces to choosing the homography that maximizes the number of inliers.</p><div class="grid grid-cols-3 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="doe left" loading="lazy" width="1500" height="1125" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeleft.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeleft.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeleft.jpg&amp;w=3840&amp;q=75"/><img alt="doe middle" loading="lazy" width="1500" height="1125" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoemiddle.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoemiddle.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoemiddle.jpg&amp;w=3840&amp;q=75"/><img alt="doe right" loading="lazy" width="1500" height="1125" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeright.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeright.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoeright.jpg&amp;w=3840&amp;q=75"/></div><div class="grid grid-cols-2 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="doe first homography" loading="lazy" width="1690" height="1250" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe1.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe1.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe1.jpg&amp;w=3840&amp;q=75"/><img alt="doe second homography" loading="lazy" width="1900" height="1000" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe2.jpg&amp;w=1920&amp;q=75 1x, /_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe2.jpg&amp;w=3840&amp;q=75 2x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fdoe%2Fdoe2.jpg&amp;w=3840&amp;q=75"/></div></div></article></div></section><section class="mb-8 mx-[5vw] rounded-[1rem] shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-fit relative bg-red undefined"><div class="h-fit"><article class="relative z-50 m-0 p-8 text-left max-w-[100%] h-fit rounded-2xl bg-white text-black undefined" id="Final Results"><div><h2>A Comparison</h2><p>Here are the results of the homography done manually vs automatically. The image on top will be the one doe manually and the one below is automatic. There is a noticeable trend that the automatic alignment and robust homography tends to do better in areas that have lots of trees. In the examples below, my manual alignment tends to result in the leaves being blurred, while the automatic alignment is much more consistent in aligning the leaves.</p><h4>Near Anthropology</h4><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="anthro manual" loading="lazy" width="3700" height="1950" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fanthro%2Fanthro.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fanthro%2Fanthro.jpg&amp;w=3840&amp;q=75"/><img alt="anthro auto" loading="lazy" width="3800" height="1950" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fanthro%2Fanthro_ransac.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fanthro%2Fanthro_ransac.jpg&amp;w=3840&amp;q=75"/></div><h4>Street Intersection</h4><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="intersection manual" loading="lazy" width="3000" height="1600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fintersection%2Finter.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fintersection%2Finter.jpg&amp;w=3840&amp;q=75"/><img alt="intersection auto" loading="lazy" width="3000" height="1600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fintersection%2Finter_ransac.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fintersection%2Finter_ransac.jpg&amp;w=3840&amp;q=75"/></div><h4>Faculty Glade</h4><div class="grid grid-cols-1 gap-4 items-center justify-center w-full max-w-[90%] mx-auto py-4 undefined"><img alt="glade manual" loading="lazy" width="3000" height="1600" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fglade%2Fglade.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fglade%2Fglade.jpg&amp;w=3840&amp;q=75"/><img alt="glade auto" loading="lazy" width="3500" height="1800" decoding="async" data-nimg="1" class="w-full" style="color:transparent" srcSet="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fglade%2Fglade_ransac.jpg&amp;w=3840&amp;q=75 1x" src="/_next/image?url=%2Fprojects%2FImageProcessing%2FProject4%2Fmedia%2FPart2%2Fresults%2Fglade%2Fglade_ransac.jpg&amp;w=3840&amp;q=75"/></div></div></article></div></section></div><div class="block flex-grow"><div class="max-w-[80%] mx-auto h-full"><div class="sticky top-[20%] p-4 pl-6 border-1 border-black border-solid rounded-[1rem] bg-black shadow-[0px_5px_15px_rgba(0,0,0,0.35)] h-auto  max-h-[60vh] overflow-y-auto "><nav><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Homographies">Homographies</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Image Warping">Image Warping</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Rectification">Rectification</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Image Mosaic">Image Mosaic</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Corner Detection">Corner Detection</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Feature Descriptors">Feature Descriptors</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Feature Matching">Feature Matching</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Robust Homography">Robust Homography</a></ul><ul><a class="block scale-90 hover:text-slate-300 transition-transform  duration-100 ease-in-out text-[1.1rem] hover:scale-100 focus:scale-100 " href="#Final Results">Final Results</a></ul></nav></div></div></div></div></div></div></div><footer class="w-full bg-black text-center p-4 text-white shadow-[0_-5px_15px_rgba(0,0,0,0.35)]"><div>&lt;&lt;&lt; © Trustin Nguyen &gt;&gt;&gt;</div><div><a class="text-white hover:text-gray-300 hover:scale-100 focus:text-gray-300 focus:scale-100" href="#"> <!-- -->Back to Top<!-- --> </a></div></footer></div><script src="./_next/static/chunks/webpack-341aa4a4d509aee2.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[4547,[],\"ClientSegmentRoot\"]\n3:I[7249,[\"177\",\"static/chunks/app/layout-52a546404f3946aa.js\"],\"default\"]\n4:I[5244,[],\"\"]\n5:I[3866,[],\"\"]\n7:I[7033,[],\"ClientPageRoot\"]\n8:I[2445,[\"173\",\"static/chunks/173-fc558b54b5be890b.js\",\"795\",\"static/chunks/795-77b345457a57fcf5.js\",\"970\",\"static/chunks/970-273da32e793c59cb.js\",\"290\",\"static/chunks/app/projects/ImageProcessing/Project4/page-ba1dac737234bc18.js\"],\"default\"]\nb:I[6213,[],\"OutletBoundary\"]\nd:I[6213,[],\"MetadataBoundary\"]\nf:I[6213,[],\"ViewportBoundary\"]\n11:I[4835,[],\"\"]\n:HL[\"./_next/static/css/bfe94c38b147c90b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"tlwXbO0V3Ne-VwUPMHTZp\",\"p\":\".\",\"c\":[\"\",\"projects\",\"ImageProcessing\",\"Project4\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"projects\",{\"children\":[\"ImageProcessing\",{\"children\":[\"Project4\",{\"children\":[\"__PAGE__\",{}]}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"./_next/static/css/bfe94c38b147c90b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"Component\":\"$3\",\"slots\":{\"children\":[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]},\"params\":{},\"promise\":\"$@6\"}]]}],{\"children\":[\"projects\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"ImageProcessing\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"Project4\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L4\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"projects\",\"children\",\"ImageProcessing\",\"children\",\"Project4\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L5\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"$L7\",null,{\"Component\":\"$8\",\"searchParams\":{},\"params\":\"$0:f:0:1:1:props:children:1:props:params\",\"promises\":[\"$@9\",\"$@a\"]}],null,[\"$\",\"$Lb\",null,{\"children\":\"$Lc\"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"2z_z4J5udzL4jmQC_nvhw\",{\"children\":[[\"$\",\"$Ld\",null,{\"children\":\"$Le\"}],[\"$\",\"$Lf\",null,{\"children\":\"$L10\"}],null]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$11\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"6:{}\n9:{}\na:{}\n"])</script><script>self.__next_f.push([1,"10:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\ne:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"link\",\"1\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]]\n"])</script><script>self.__next_f.push([1,"c:null\n"])</script></body></html>